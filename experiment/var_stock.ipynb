{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from datetime import date\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1990\n",
    "N_CLUSTERS = 8\n",
    "WINDOW_SIZE = 100\n",
    "VAR_PERCENTILE_LEVEL = 5\n",
    "METRIC = \"dtw\"\n",
    "FONT = {'family': 'serif',\n",
    "        'color':  'black',\n",
    "        'weight': 'normal',\n",
    "        'size': 20,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data from the local database. If the API or local database are not working, load the csv file directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    connection = pg.connect(database=\"postgres\", user=\"postgres\", password=\"Crypto01\", host=\"localhost\", port=5430)\n",
    "    cur = connection.cursor()\n",
    "    cur.execute(\"SELECT * FROM input.stock_daily_changes ORDER BY date DESC\")\n",
    "    data = sorted(cur.fetchall(), key=lambda row: row[0], reverse=False)\n",
    "    data = pd.DataFrame(data=data, columns=[desc[0] for desc in cur.description], index=[row[0] for row in data], dtype=\"float64\")\n",
    "except:\n",
    "    try:\n",
    "        data = pd.read_csv(\"./stock_daily_changes.csv\", sep=\",\")\n",
    "        data = data.sort_values(by=\"date\", ascending=True)\n",
    "        data.index = pd.to_datetime(data.date).dt.date\n",
    "    except:\n",
    "        raise Exception(\"Unable to read data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_changes = data.drop([\"date\"], axis=1)\n",
    "daily_changes = daily_changes[daily_changes.index <= date(2018, 7, 31)]\n",
    "daily_changes = daily_changes[daily_changes.index >= date(2016, 1, 1)]\n",
    "daily_changes = daily_changes - 1\n",
    "transpose_df = daily_changes.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daily return/change dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposed daily return/change dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transpose_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = daily_changes.corr()\n",
    "cryptos = np.array(corr_mat.columns)\n",
    "plt.clf()\n",
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "plt.matshow(corr_mat)\n",
    "plt.xticks(range(len(cryptos)), cryptos, rotation=\"vertical\", fontsize=24)\n",
    "plt.yticks(range(len(cryptos)), cryptos, fontsize=24)\n",
    "\n",
    "ax = plt.gca()\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "\n",
    "plt.colorbar(cax=cax)\n",
    "plt.tick_params(labelsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the transposed dataframe into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose_array = np.array(transpose_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the cumulative explained variance percentage of PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_plot = PCA(n_components=29)\n",
    "pca_plot.fit(transpose_array)\n",
    "\n",
    "cumsum_variance_ratio = np.cumsum(pca_plot.explained_variance_ratio_)\n",
    "pc_names = [\"PC\" + str(i) for i in range(1, 30)]\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(cumsum_variance_ratio, color=\"darkorange\")\n",
    "plt.bar(range(0, 29), pca_plot.explained_variance_ratio_, color=\"blue\")\n",
    "plt.yticks(fontsize=24)\n",
    "plt.xticks(range(0, 29), pc_names, rotation=40, fontsize=24)\n",
    "plt.xlabel(\"Principal Component\", fontdict=FONT, fontsize=28)\n",
    "plt.ylabel(\"Explained Variance Percentage\", fontdict=FONT, fontsize=28)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement PCA and K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=27)\n",
    "pca_array = pca.fit_transform(transpose_array)\n",
    "dba_km = TimeSeriesKMeans(n_clusters=N_CLUSTERS, max_iter=100, metric=METRIC, verbose=True, max_iter_barycenter=10, random_state=SEED)\n",
    "pred_clusters = dba_km.fit_predict(pca_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explained variance percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of interpretation:\", sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in set(pred_clusters):\n",
    "    print(\"Cluster\", cluster + 1, \":\", cryptos[np.where(pred_clusters == cluster)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.clf()\n",
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "for yi in set(pred_clusters):\n",
    "    plt.subplot(N_CLUSTERS/2 + 1, 2, yi + 1)\n",
    "    for xx in pca_array[pred_clusters == yi]:\n",
    "        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "    plt.plot(dba_km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "    plt.xlim(0, pca_array.shape[1])\n",
    "    plt.ylim(-0.2, 0.2)\n",
    "    title = \"Cluster : \" + str(yi + 1)\n",
    "    plt.title(title, fontdict=FONT, fontsize=32)\n",
    "    plt.xticks(fontsize=24)\n",
    "    plt.yticks(fontsize=24)\n",
    "    if yi % 2 == 0 :\n",
    "        plt.ylabel(\"Return\", rotation=\"vertical\", fontdict=FONT, fontsize=28)\n",
    "    if yi == 6 or yi == 7:\n",
    "        plt.xlabel(\"Principal Component\", fontdict=FONT, fontsize=28)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VaR estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_arr_before = []\n",
    "vars_arr_after = []\n",
    "\n",
    "for i in range(0, transpose_array.shape[1] - WINDOW_SIZE):\n",
    "    vars_arr_before.append([np.percentile(row, VAR_PERCENTILE_LEVEL) for row in transpose_array[:, i: i + WINDOW_SIZE]])\n",
    "    cluster_vars = [None] * 29\n",
    "    for j in set(pred_clusters):\n",
    "        var = np.percentile(np.hstack(transpose_array[pred_clusters == j, i: i + WINDOW_SIZE]), VAR_PERCENTILE_LEVEL)\n",
    "        for k in np.where(pred_clusters == j)[0]:\n",
    "            cluster_vars[k] = var\n",
    "    vars_arr_after.append(cluster_vars)\n",
    "\n",
    "vars_arr_before = np.array(vars_arr_before).transpose()\n",
    "vars_df_before = pd.DataFrame(vars_arr_before, columns=transpose_df.columns[WINDOW_SIZE:], index=daily_changes.columns)\n",
    "vars_arr_after = np.array(vars_arr_after).transpose()\n",
    "vars_df_after = pd.DataFrame(vars_arr_after, columns=transpose_df.columns[WINDOW_SIZE:], index=daily_changes.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VaRs before clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vars_df_before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VaRs after clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vars_df_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VaR performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_before = np.array([np.sum(transpose_array[i, WINDOW_SIZE:] > vars_arr_before[i, :]) / vars_arr_before.shape[1] for i in range(0, vars_arr_before.shape[0])])\n",
    "accuracies_before = pd.DataFrame(accuracies_before, columns=[\"Accuracy\"], index=daily_changes.columns)\n",
    "accuracies_after = np.array([np.sum(transpose_array[i, WINDOW_SIZE:] > vars_arr_after[i, :]) / vars_arr_after.shape[1] for i in range(0, vars_arr_after.shape[0])])\n",
    "accuracies_after = pd.DataFrame(accuracies_after, columns=[\"Accuracy\"], index=daily_changes.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VaR performance before clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracies_before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VaR performance after clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracies_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average accuracy before clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average accuracy before clustering:\", np.mean(np.array(accuracies_before)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average accuracy after clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average accuracy after clustering:\", np.mean(np.array(accuracies_after)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value of exactly 5% before clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(0, 29):\n",
    "    count += np.sum(transpose_array[i, WINDOW_SIZE:] < vars_arr_before[i, :]) == 27\n",
    "p_value_equal_before = count/29\n",
    "\n",
    "print(\"p-value of exactly 5% before clustering:\", p_value_equal_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value of exactly 5% after clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(0, 29):\n",
    "    count += np.sum(transpose_array[i, WINDOW_SIZE:] < vars_arr_after[i, :]) == 27\n",
    "p_value_equal_after = count/29\n",
    "\n",
    "print(\"p-value of exactly 5% after clustering:\", p_value_equal_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 sided p-value before clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(0, 29):\n",
    "    count += np.sum(transpose_array[i, WINDOW_SIZE:] < vars_arr_before[i, :]) >= 29\n",
    "p_value_1side_before = count/29\n",
    "\n",
    "print(\"1 sided p-value of underestimation before clustering:\", p_value_1side_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 sided p-value after clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(0, 29):\n",
    "    count += np.sum(transpose_array[i, WINDOW_SIZE:] < vars_arr_after[i, :]) >= 29\n",
    "p_value_1side_after = count/29\n",
    "\n",
    "print(\"1 sided p-value of underestimation after clustering:\", p_value_1side_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 sided p-value before clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(0, 29):\n",
    "    count += np.sum(transpose_array[i, WINDOW_SIZE:] < vars_arr_before[i, :]) <= 25 or np.sum(transpose_array[i, WINDOW_SIZE:] < vars_arr_before[i, :]) >= 29\n",
    "p_value_2side_before = count/29\n",
    "\n",
    "print(\"2 sided p-value before clustering:\", p_value_2side_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 sided p-value after clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(0, 29):\n",
    "    count += np.sum(transpose_array[i, WINDOW_SIZE:] < vars_arr_after[i, :]) <= 25 or np.sum(transpose_array[i, WINDOW_SIZE:] < vars_arr_after[i, :]) >= 29\n",
    "p_value_2side_after = count/29\n",
    "\n",
    "print(\"2 sided p-value after clustering:\", p_value_2side_after)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
